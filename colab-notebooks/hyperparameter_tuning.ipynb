{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter-tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzbUm6o4v6aCJS5JE5KUvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmusau17/AAF1Tenth/blob/master/colab-notebooks/hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBaqoerk1d5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#libraries\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "import csv\n",
        "import glob\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from keras.optimizers import Adam,rmsprop\n",
        "from keras.models import model_from_json, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model,Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "from keras.layers.convolutional import Deconv2D as Conv2DTranspose\n",
        "from keras.layers import Lambda, Input, Dense, MaxPooling2D, BatchNormalization,Input\n",
        "from keras.layers import UpSampling2D, Dropout, Flatten, Reshape, RepeatVector, LeakyReLU,Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "np.random.seed(7)\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import History \n",
        "import random\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "import prettytable\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xroZu_0p5ee-",
        "colab_type": "code",
        "outputId": "bd976606-6369-4f5a-c3e9-e4fb477748b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4SJ-tGNkOeY",
        "colab_type": "code",
        "outputId": "da45d2be-8e16-4605-da90-e6d747c60ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/gdrive/My Drive\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'A Decentralized Framework for Collision Free Multi-Robot Navigation.gslides'\n",
            "'A Fog-Aware Adaptive Framework for Optimizing the Performance of Resource Constrained Self-driving Robots.gslides'\n",
            " AnomalyDetectionVAE\n",
            "'Assurance Framework.pptx'\n",
            " Beta-VAE-New-Results.gslides\n",
            "'B-VAE For Novelty Detection  .gslides'\n",
            " carla-different-weather.mp4\n",
            " carla-same-weather.mp4\n",
            "'Car Supplies.gsheet'\n",
            "'Change Point Detection for Perception Based Systems.gslides'\n",
            "'Change Point Detection for Perception Based Systems.pptx'\n",
            "'Colab Notebooks'\n",
            "'Collaborators List-Dubey-FINAL.gsheet'\n",
            "'Collaborators List-Dubey-FINAL.xlsx'\n",
            "'DeepNNCar (1).gslides'\n",
            " DeepNNCar_2019\n",
            " DeepNNCar-Framework.gslides\n",
            " DeepNNCar.gslides\n",
            " DeepNNCar.pptx\n",
            "'Designing Safety Cases for DeepNNCar.gdoc'\n",
            " DrawIO\n",
            "'Emergency braking example.docx'\n",
            "'Emergency braking example.gdoc'\n",
            "'Experiment Section Carla.gdoc'\n",
            " frame3097.png\n",
            " Framework.gslides\n",
            "'Framework to identify out-of-distribution images.gslides'\n",
            "'Identifying Out-of distribution Images using VAE.gslides'\n",
            " IMG_0139.MOV\n",
            "'IoTLib: A Component library for designing IoT Architectures.gslides'\n",
            " ISORC2020\n",
            " ISORC-JOURNAL-ADDITIONS.gdoc\n",
            "'Latent Space Exploration using VAE (math + experiment results).gslides'\n",
            "'MIG Score and Latent Variables selection to design anomaly monitors.gdoc'\n",
            "'Outlier Detection.gslides'\n",
            " Presentation1.pptx\n",
            " ProjectDescription.gslides\n",
            " ProjectDescription.pptx\n",
            "'Rebuttal for the ISORC Paper.gdoc'\n",
            "'Rebuttal for the ISORC Paper-new.gdoc'\n",
            "'Result Analysis.pptx'\n",
            " RLDeepNNCar.gslides\n",
            " RL-SImplex.gslides\n",
            "'Safety-Assurance Literature'\n",
            "'Some Slides.gslides'\n",
            " somework.gslides\n",
            "'Speed vs inference time.gslides'\n",
            " sunny-train\n",
            " sunny-train.csv\n",
            " sunny-train.zip\n",
            "'TORCS Program Flow.gslides'\n",
            " Torcs-summary.gslides\n",
            " Transax-slides_ad.gslides\n",
            "'Untitled presentation (1).gslides'\n",
            "'Untitled presentation.gslides'\n",
            " VAE-Slides.gslides\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McLcM4X5aLRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/sunny-train.zip\" -d \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-DoIo9f2pzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path to USB\n",
        "USBPath = \"/content/gdrive/My Drive/\"\n",
        "trainingFolders = [\"sunny-train\"]\n",
        "history = CSVLogger(USBPath + '/kerasloss.csv', append=True, separator=';')\n",
        "\n",
        "#Load complete input images without shuffling\n",
        "def load_images(paths):\n",
        "    numImages = 0\n",
        "    inputs = []\n",
        "    for path in paths:\n",
        "        numFiles = len(glob.glob1(path,'*.png'))\n",
        "        numImages += numFiles\n",
        "        for img in glob.glob(path+'*.png'):\n",
        "            img = cv2.imread(img)\n",
        "            img = cv2.resize(img, (200,66))\n",
        "            img = img /255.\n",
        "            inputs.append(img)\n",
        "    #inpu = shuffle(inputs)\n",
        "    print(\"Total number of images:%d\" %(numImages))\n",
        "    return inputs\n",
        "\n",
        "def createFolderPaths(folders):\n",
        "    paths = []\n",
        "    for folder in folders:\n",
        "        path = USBPath + folder + '/'\n",
        "        paths.append(path)\n",
        "    return paths\n",
        "\n",
        "def load_training_images():\n",
        "    paths = createFolderPaths(trainingFolders)\n",
        "    return load_images(paths)\n",
        "\n",
        "def load_steering_value():\n",
        "    miny= -1\n",
        "    maxy= 1\n",
        "    Y=[]\n",
        "    dataset = \"/content/gdrive/My Drive/\" + '/sunny-train.csv'\n",
        "    with open(dataset, 'rt') as csvfile:\n",
        "          reader = csv.reader(csvfile)\n",
        "          for row in reader:\n",
        "            output=[]\n",
        "            x=(float(row[0])-miny)/(maxy-miny)\n",
        "            output.append(x)\n",
        "            Y.append(output)\n",
        "    return Y        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V3DSVNF2s8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading images from the datasets\n",
        "image_input = load_training_images()\n",
        "steer_output = load_steering_value()\n",
        "print(\"Total Steering values:%d\"%len(steer_output))\n",
        "image_input = np.array(image_input)\n",
        "steer_output = np.array(steer_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giqkwo4R2voI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN-VAE model.\n",
        "def createModel():\n",
        "\n",
        "    model = Sequential()\n",
        "    input= Input(shape=(66,200,3), name='image')\n",
        "    steer_inp = BatchNormalization(epsilon=0.001, axis=-1,momentum=0.99)(input)\n",
        "    layer1 = Conv2D(24, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(steer_inp)\n",
        "    layer2 = Conv2D(36, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(layer1)\n",
        "    layer3 = Conv2D(48, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(layer2)\n",
        "    layer4 = Conv2D(64, (3, 3), padding=\"valid\", strides=(1, 1), activation=\"relu\")(layer3)\n",
        "    layer5 = Conv2D(64, (3, 3), padding=\"valid\", strides=(1, 1), activation=\"relu\")(layer4)\n",
        "    layer6 = Flatten()(layer5)\n",
        "    layer7 = Dense(1164, activation='relu')(layer6)\n",
        "    layer8 = Dense(100, activation='relu')(layer7)\n",
        "    layer9 = Dense(10, activation='relu')(layer8)\n",
        "    steer_out = Dense(1, activation='tanh')(layer9)\n",
        "    model=Model(inputs=input, outputs=steer_out)\n",
        "  \n",
        "    return model\n",
        "\n",
        "#training the model with different hyperparameters\n",
        "def trainModel(model, X, Y,e,b):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.05,random_state=42)\n",
        "    adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    model.compile(loss='mse', optimizer=adam, metrics=[\"MAE\"])\n",
        "    callbacks_list = [EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=0),]\n",
        "    #ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)]\n",
        "    hist=model.fit(X_train, Y_train, epochs=e, batch_size=b,validation_data=(X_test, Y_test),callbacks=callbacks_list, verbose=0)\n",
        "    return hist\n",
        "\n",
        "#function for arranging list in descending order\n",
        "def takeFirst(elem):\n",
        "    return elem[2]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EMTpMJT2wXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results(rand_x,rand_y,epochs,batches,iterations):#Plot to analyze the state space sampling\n",
        "        x_lims = [np.min(epochs), np.max(epochs)]\n",
        "        y_lims = [np.min(batches), np.max(batches)]\n",
        "        plt.scatter(rand_x, rand_y, c=['blue']*iterations)\n",
        "        plt.gca().set(xlabel='epochs', ylabel='batch_size',title='Hyperparameters Search Space')\n",
        "        plt.show()\n",
        "\n",
        "def hyperparameter_search(trial,iterations,epochs,batches):\n",
        "    selection=[]\n",
        "    loss = []\n",
        "    rand_x = []\n",
        "    rand_y = []\n",
        "    model = createModel()# create model\n",
        "    \n",
        "    if(trial == \"random\"):#random search\n",
        "        time1=time.time()\n",
        "        combinations_list = [list(x) for x in product(epochs, batches)]\n",
        "        random_combinations_index = np.random.choice(range(0,len(combinations_list)), iterations, replace=False)\n",
        "        combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
        "        print(combinations_random_chosen)#printing chosen random combination\n",
        "        for i in range(iterations):\n",
        "            rand_x.append(combinations_random_chosen[i][0])\n",
        "            rand_y.append(combinations_random_chosen[i][1])\n",
        "            print(\"**********************epoch=%d,batch=%d*********************\"%(combinations_random_chosen[i][0],combinations_random_chosen[i][1]))\n",
        "            loss_val=trainModel(model, image_input, steer_output, combinations_random_chosen[i][0], combinations_random_chosen[i][1])#train model with new hyperparameters\n",
        "            loss.append((combinations_random_chosen[i][0],combinations_random_chosen[i][1], loss_val.history['loss'][-1]))#extract and append loss from last epoch\n",
        "            loss.sort(key=takeFirst,reverse=False)#sort list to get the hyperparameters resulting in least loss\n",
        "            print(loss[0])\n",
        "            selection.append(loss[0])\n",
        "        print(\"Tuning Time=%f\"%(time.time()-time1))\n",
        "        selection.sort(key=takeFirst,reverse=False)\n",
        "        t = PrettyTable(['Epoch','Batch_size','Loss'])#print results in Table\n",
        "        for values in selection:\n",
        "            t.add_row([values[0],values[1],values[2]])\n",
        "        print(t)\n",
        "        print(\"******The selected hyperparameters and loss are******\")\n",
        "        print(\"Batch_size=%d Epochs=%d loss=%f\"%(selection[0][0],selection[0][1],selection[0][2]))\n",
        "        \n",
        "        plot_results(rand_x,rand_y,epochs,batches,iterations)#Plot to analyze the hyperparameter combination\n",
        "        \n",
        "\n",
        "    if(trial == \"grid\"):#grid search\n",
        "        time1=time.time()\n",
        "        combinations_list = [list(x) for x in product(epochs, batches)]\n",
        "        for combinations_random_chosen in (combinations_list):\n",
        "            rand_x.append(combinations_random_chosen[0])\n",
        "            rand_y.append(combinations_random_chosen[1])\n",
        "            print(\"**********************epoch=%d,batch=%d*********************\"%(combinations_random_chosen[0],combinations_random_chosen[1]))\n",
        "            loss_val=trainModel(model, image_input, steer_output, combinations_random_chosen[0], combinations_random_chosen[1])#train model with new hyperparameters\n",
        "            loss.append((combinations_random_chosen[0],combinations_random_chosen[1], loss_val.history['loss'][-1]))#extract and append loss from last epoch\n",
        "            loss.sort(key=takeFirst,reverse=False)#sort list to get the hyperparameters resulting in least loss\n",
        "            print(loss[0])\n",
        "            selection.append(loss[0])\n",
        "        print(\"Tuning Time=%f\"%(time.time()-time1))\n",
        "        selection.sort(key=takeFirst,reverse=False)\n",
        "        t = PrettyTable(['Epoch','Batch_size','Loss'])#print results in Table\n",
        "        for values in selection:\n",
        "            t.add_row([values[0],values[1],values[2]])\n",
        "        print(t)\n",
        "        print(\"******The selected hyperparameters and loss are******\")\n",
        "        print(\"Batch_size=%d Epochs=%d loss=%f\"%(selection[0][0],selection[0][1],selection[0][2]))\n",
        "        \n",
        "        plot_results(rand_x,rand_y,epochs,batches,len(combinations_list))#Plot to analyze the hyperparameter combination\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zpFwOQM2zmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = [1,2,4]#hyperparameter1\n",
        "batches = [16,32]#hyperparameter2\n",
        "trial = \"random\" #choose what kind of hyperparameter selection algorithm to use\n",
        "iterations = 2 #For random search select how many random samples have to be chosen\n",
        "hyperparameter_search(trial,iterations,epochs,batches)# call the hyperparameter tuning function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJxSyHBL6pjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}